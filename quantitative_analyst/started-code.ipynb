{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bf264d",
   "metadata": {},
   "source": [
    "## Quant Analyst Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4600d8",
   "metadata": {},
   "source": [
    "#### 1. Given “Employee” table below:\n",
    "\n",
    "| id | Name | Salary | manager_id |\n",
    "|----|------|--------|------------|\n",
    "| 1 | John  | 300    | 3 |\n",
    "| 2 | Mike  | 200    | 3 |\n",
    "| 3 | Sally | 550    | 4 |\n",
    "| 4 | Jane  | 500    | 7 |\n",
    "| 5 | Joe   | 600    | 7 |\n",
    "| 6 | Dan   | 600    | 3 |\n",
    "| 7 | Phil  | 550    | NULL |\n",
    "|...|  ...  |  ...   |...|\n",
    "\n",
    "  - Give the name of employees, whose salaries are greater than their immediate\n",
    "manager’s\n",
    "  - What is the average salary of employees who do not manage anyone? In the sample\n",
    "above, that would be John, Mike, Joe and Dan, since they do not have anyone\n",
    "reporting to them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a780e",
   "metadata": {},
   "source": [
    "We can answer both of these using SQL query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a43c3",
   "metadata": {},
   "source": [
    "> Give the name of employees, whose salaries are greater than their immediate manager’s\n",
    "\n",
    "```\n",
    "SELECT e2.name\n",
    "FROM employee e1\n",
    "JOIN employee e2\n",
    "ON e1.id = e2.manager_id\n",
    "WHERE e2.salary > e1.salary;\n",
    "```\n",
    "\n",
    "_Reasoning_: We do a self-join to get a list of entries on the condition which matches employee's id to their manager's id. Now the \"second\" table is the one that has list of employees, that's the table we are interested in. Then we compare whose salary from that table is higher than the employees in \"first\" table, which contains the details of their managers. For the table we get the result: `Dan | Sally | Joe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cff7fd",
   "metadata": {},
   "source": [
    "> What is the average salary of employees who do not manage anyone?\n",
    "\n",
    "```\n",
    "SELECT AVG(salary)\n",
    "FROM employee\n",
    "WHERE name NOT IN (\n",
    "\tSELECT e1.name\n",
    "\tFROM employee e1\n",
    "\tJOIN employee e2\n",
    "\tON e1.id = e2.manager_id)\n",
    "```\n",
    "\n",
    "_Reasoning_: We use a similar approach as before. Self join the table on id and manager_id, but this time to get a list of employees from \"first\" table i.e. people who are managers. Then we use it as a subquery to get the list of names that aren't anyone's manager. Once we have that, we can simply take an average of the salary, which in this case is `425.00`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eea647",
   "metadata": {},
   "source": [
    "#### 2. Write a function ‘exists’ which takes a variable symbol v and returns whether v is defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617022a3",
   "metadata": {},
   "source": [
    "In python, it is quite straight-forward to check if a variable exists using an `if` statement. However, when we use a function to check if a variable exists or not, we need to specify if it is _local_ or _global_ variable. From the context of this question, we can assume that we are looking for a global variable. In that case, the `exists()` function can be defined as below. The function returns a boolean True/False as result.\n",
    "\n",
    "_Note_: Since we are checking for global variable we need to make sure we pass the name of the variable as argument because the function `globals()` returns a dictionary of all global varibales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57aa5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if a varible exists\n",
    "def exists(v):\n",
    "    # check if the variable exists in the globals\n",
    "    if v in globals():\n",
    "        # if it exists, return True\n",
    "        return True\n",
    "    else:\n",
    "        # else, return False\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54693e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exists('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5206991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = 5\n",
    "exists('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc68864",
   "metadata": {},
   "source": [
    "#### 3. Create a function to compute N layer of a Pascal Triangle. The first 4 later will looks like:\n",
    "1\n",
    "\n",
    "1 1\n",
    "\n",
    "1 2 1\n",
    "\n",
    "1 3 3 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b903f1a",
   "metadata": {},
   "source": [
    "We will write a python function to create the Pascal Triangle, which takes `N` as input and returns the pascal triangle of `N` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecef8769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print pascal's triangle\n",
    "def print_pascal_tri(lst):\n",
    "    for row in lst:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac3337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create pascal triangle of N layers\n",
    "def pascal_triangle(N):\n",
    "    # instantiate an empty list to store the layers\n",
    "    pascal_tri_list = []\n",
    "    \n",
    "    # run a for loop for N number of times\n",
    "    for i in range(N):\n",
    "        # list of numbers in each layer\n",
    "        layer = []\n",
    "        \n",
    "        if not pascal_tri_list: # if the full list is empty, append 1\n",
    "            layer.append(1)\n",
    "        else: # else insert the intermediate numbers\n",
    "            # get the length of the previous layer\n",
    "            prev_layer_len = len(pascal_tri_list[i-1])\n",
    "            \n",
    "            # run a second loop one more than previous layer's length\n",
    "            for j in range(prev_layer_len + 1):\n",
    "                # for the first two layers just add 1s\n",
    "                if j == 0 or j == 1:\n",
    "                    layer.append(1)\n",
    "                else:\n",
    "                    # insert the sum of top two numbers at previous index\n",
    "                    layer.insert(j-1, pascal_tri_list[i-1][j-2] + pascal_tri_list[i-1][j-1])\n",
    "                    \n",
    "        # append the layer to final list\n",
    "        pascal_tri_list.append(layer)\n",
    "    \n",
    "    # print the pascal's triangle\n",
    "    print_pascal_tri(pascal_tri_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc61a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 1]\n",
      "[1, 2, 1]\n",
      "[1, 3, 3, 1]\n",
      "[1, 4, 6, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "pascal_triangle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba1383d",
   "metadata": {},
   "source": [
    "_Reasoning_: The comments should be enough to follow along. Basically, we are running a for loop, and at every step checking the previous layer to update the current layer. At the end, in python, it is a list of lists and we print the results. This is a brute force of getting the result and am sure there's an efficient way to solve this by taking advantage of the fact that Pascal's Triangle is an arrangement of binomial coefficients. Using multiple for loops and lists is neither memory nor compute efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aea4a2",
   "metadata": {},
   "source": [
    "#### 4. Assume have the following portfolio as of 2016/01/01:\n",
    "|      |   |\n",
    "|------|---|\n",
    "|AAPL.O|15%|\n",
    "|IBM.N |20%|\n",
    "|GOOG.O|20%|\n",
    "|BP.N  |15%|\n",
    "|XOM.N |10%|\n",
    "|COST.O|15%|\n",
    "|GS.N  |5% |\n",
    "\n",
    "  - Using historical daily returns (Yahoo/Google Finance or any other market data\n",
    "source), calculate VaR95% and CVaR95% of the portfolio as of 2016/12/31\n",
    "  - Using expected mean, covariance matrix and parametric method, calculate VaR95%\n",
    "and CVaR95%\n",
    "  - Assume you can change weights, allow shorting but no leverage (i.e. sum of weights\n",
    "equal 100%), and rebalance monthly. What is the optimal portfolio holding by end of\n",
    "each month till end of 2016\n",
    "\n",
    "_Notes_: If you have other assumption(s) please state clearly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea564a",
   "metadata": {},
   "source": [
    "First, downloaded some historical daily stock data from [Yahoo finance](https://finance.yahoo.com/) for all the stocks in the portfolio. Saved them as text csv files in the _datesets_ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3de6d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05f65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the stock data as pandas dataframe\n",
    "aapl = pd.read_csv('datasets/AAPL.csv')\n",
    "ibm = pd.read_csv('datasets/IBM.csv')\n",
    "goog = pd.read_csv('datasets/GOOG.csv')\n",
    "bp = pd.read_csv('datasets/BP.csv')\n",
    "xom = pd.read_csv('datasets/XOM.csv')\n",
    "cost = pd.read_csv('datasets/COST.csv')\n",
    "gs = pd.read_csv('datasets/GS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bae7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all stocks in portfolio\n",
    "port_list = ['AAPL', 'IBM', 'GOOG', 'BP', 'XOM', 'COST', 'GS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69c36da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>IBM</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>BP</th>\n",
       "      <th>XOM</th>\n",
       "      <th>COST</th>\n",
       "      <th>GS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         AAPL  IBM  GOOG    BP  XOM  COST    GS\n",
       "Weights  0.15  0.2   0.2  0.15  0.1  0.15  0.05"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our portfolio\n",
    "port = pd.DataFrame([0.15, 0.20, 0.20, 0.15, 0.10, 0.15, 0.05],\n",
    "                    index=port_list,\n",
    "                    columns=['Weights']).T\n",
    "port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebf1039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to add the return column to the dataframes\n",
    "def add_return(df):\n",
    "    df['Return'] = df['Adj Close'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36a5198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the function on all individual stock dataframes\n",
    "add_return(aapl)\n",
    "add_return(ibm)\n",
    "add_return(goog)\n",
    "add_return(bp)\n",
    "add_return(xom)\n",
    "add_return(cost)\n",
    "add_return(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c4d000b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>IBM</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>BP</th>\n",
       "      <th>XOM</th>\n",
       "      <th>COST</th>\n",
       "      <th>GS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>-0.025059</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-0.004185</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>-0.017219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-06</th>\n",
       "      <td>-0.019570</td>\n",
       "      <td>-0.005006</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>-0.020369</td>\n",
       "      <td>-0.008321</td>\n",
       "      <td>-0.009254</td>\n",
       "      <td>-0.024412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-07</th>\n",
       "      <td>-0.042205</td>\n",
       "      <td>-0.017090</td>\n",
       "      <td>-0.023170</td>\n",
       "      <td>-0.028713</td>\n",
       "      <td>-0.016006</td>\n",
       "      <td>-0.022909</td>\n",
       "      <td>-0.030735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-08</th>\n",
       "      <td>0.005288</td>\n",
       "      <td>-0.009258</td>\n",
       "      <td>-0.016410</td>\n",
       "      <td>-0.017669</td>\n",
       "      <td>-0.020202</td>\n",
       "      <td>-0.017504</td>\n",
       "      <td>-0.004131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.001706</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>-0.001761</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>-0.004264</td>\n",
       "      <td>-0.005684</td>\n",
       "      <td>-0.008212</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>-0.004959</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>-0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>-0.000257</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>-0.002879</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>-0.010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>-0.007796</td>\n",
       "      <td>-0.003662</td>\n",
       "      <td>-0.014014</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.006330</td>\n",
       "      <td>0.005332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL       IBM      GOOG        BP       XOM      COST  \\\n",
       "Date                                                                     \n",
       "2016-01-04       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2016-01-05 -0.025059 -0.000735  0.000998 -0.004185  0.008521  0.002444   \n",
       "2016-01-06 -0.019570 -0.005006  0.001400 -0.020369 -0.008321 -0.009254   \n",
       "2016-01-07 -0.042205 -0.017090 -0.023170 -0.028713 -0.016006 -0.022909   \n",
       "2016-01-08  0.005288 -0.009258 -0.016410 -0.017669 -0.020202 -0.017504   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2016-12-23  0.001978 -0.002095 -0.001706  0.002981 -0.001761  0.000062   \n",
       "2016-12-27  0.006351  0.002579  0.002076  0.002431  0.000441 -0.000185   \n",
       "2016-12-28 -0.004264 -0.005684 -0.008212  0.003772 -0.004959 -0.006418   \n",
       "2016-12-29 -0.000257  0.002467 -0.002879  0.004027  0.000554  0.000745   \n",
       "2016-12-30 -0.007796 -0.003662 -0.014014 -0.000535 -0.000996 -0.006330   \n",
       "\n",
       "                  GS  \n",
       "Date                  \n",
       "2016-01-04       NaN  \n",
       "2016-01-05 -0.017219  \n",
       "2016-01-06 -0.024412  \n",
       "2016-01-07 -0.030735  \n",
       "2016-01-08 -0.004131  \n",
       "...              ...  \n",
       "2016-12-23  0.003540  \n",
       "2016-12-27  0.002448  \n",
       "2016-12-28 -0.003767  \n",
       "2016-12-29 -0.010264  \n",
       "2016-12-30  0.005332  \n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a stocks dataframe with the returns for all stocks\n",
    "stocks = pd.DataFrame([aapl.Return, ibm.Return, goog.Return, bp.Return, xom.Return, cost.Return, gs.Return],\n",
    "                      index=port_list).T\n",
    "stocks.set_index(aapl.Date, inplace=True)\n",
    "stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16dd0a",
   "metadata": {},
   "source": [
    "> Using historical daily returns (Yahoo/Google Finance or any other market data source), calculate VaR95% and CVaR95% of the portfolio as of 2016/12/31\n",
    "\n",
    "Value-at-Risk aka VaR is a risk evaluation for an investment over a period of time calculated as a loss in a certain confidence interval. VaR95%, in this case, can mean the value with 5% risk of loss.\n",
    "\n",
    "Conditional-Value-at-Risk is an average loss when the VaR is exceeded. Similarly CVaR95% would mean the average value with 5% risk of loss after the VaR has exceeded.\n",
    "\n",
    "Using historical data, VaR is calculated from the returns of each stock. It is the lower 5% quartile (0.05 quantile = 5% quartile) of the returns. Taking the average of all the returns below 5% quartile gives the CVaR.\n",
    "\n",
    "_Note_: This method assumes normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e068b313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL   -0.023107\n",
       "IBM    -0.018298\n",
       "GOOG   -0.020876\n",
       "BP     -0.029093\n",
       "XOM    -0.019518\n",
       "COST   -0.017777\n",
       "GS     -0.025022\n",
       "Name: 0.05, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 5% quartile for stock returns\n",
    "stocks.quantile(0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca4a9e",
   "metadata": {},
   "source": [
    "To calculate the VaR of the portfolio we multiply the respective stock with the stock weight in our portfolio and add them up to get the total VaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc5d50af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0231074 , -0.01829782, -0.02087635, -0.02909263, -0.01951797,\n",
       "       -0.01777668, -0.02502246])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of values of 5% quartile of stock returns\n",
    "stocks.quantile(0.05).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b9baf82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.2 , 0.2 , 0.15, 0.1 , 0.15, 0.05])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of values of stock weights in our portfolio\n",
    "port.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc780698",
   "metadata": {},
   "source": [
    "We need to multiply these two vectors and add them together. Mathematically, this is a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe495d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.02153425940085934"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform dot product on the above two arrays to get VaR95%\n",
    "var95_hist = port.values[0].dot(stocks.quantile(0.05).values)\n",
    "var95_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21935de8",
   "metadata": {},
   "source": [
    "So, the Value-at-Risk with 5% probability of loss is 2.15%. Next, for CVaR, we need to calculate average of all the returns in the lower 5% quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1b46040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL   -0.033328\n",
       "IBM    -0.029571\n",
       "GOOG   -0.031524\n",
       "BP     -0.041237\n",
       "XOM    -0.025815\n",
       "COST   -0.023700\n",
       "GS     -0.038277\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average of all returns below 5% stock returns quartile\n",
    "stocks[stocks.apply(lambda x: x < x.quantile(0.05))].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a8c347",
   "metadata": {},
   "source": [
    "To calculate CVaR of the portfolio we multiply the respective stock with the stock weight in our portfolio and add them up to get the total CVaR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2064588f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03332801, -0.02957119, -0.03152437, -0.0412372 , -0.02581501,\n",
       "       -0.02370047, -0.03827725])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of values of average of 5% quartile of stock returns\n",
    "stocks[stocks.apply(lambda x: x < x.quantile(0.05))].mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "399c3750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.2 , 0.2 , 0.15, 0.1 , 0.15, 0.05])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of values of stock weights in our portfolio\n",
    "port.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35e91ba",
   "metadata": {},
   "source": [
    "Similar to before, we need to multiply these two vectors and add them together. Mathematically, this is a dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38d87b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03145432615142683"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform dot product on the above two arrays to get CVaR95%\n",
    "cvar95_hist = port.values[0].dot(stocks[stocks.apply(lambda x: x < x.quantile(0.05))].mean().values)\n",
    "cvar95_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de957fc8",
   "metadata": {},
   "source": [
    "So, the Conditional-Value-at-Risk after the VaR exceeds is 3.14% with 5% probability of loss. The results can be summarized in the table below:\n",
    "\n",
    "|            | VaR95% | CVaR95% |\n",
    "|------------|--------|---------|\n",
    "| Historical |  2.15% |  3.14%  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb69d468",
   "metadata": {},
   "source": [
    "> Using expected mean, covariance matrix and parametric method, calculate VaR95% and CVaR95%\n",
    "\n",
    "The second method that can be used to calculate the VaR and CVaR is parametric method. Here, we calculate the mean and standard deviation of the returns and calculate the `norm` by generating the normal distribution from these values and the desired level of confidence. This gives the VaR using the formula\n",
    "\n",
    "VaR95 = norm.ppf(0.95)*std - mean\n",
    "\n",
    "and CVaR using the formula\n",
    "\n",
    "CVaR95 = (1-0.95)^-1 * norm.pdf(norm.ppf(1-0.95))*std - mean\n",
    "\n",
    "Source: https://quantatrisk.com/2016/12/08/conditional-value-at-risk-normal-student-t-var-model-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41887c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL    0.000574\n",
       "IBM     0.001022\n",
       "GOOG    0.000236\n",
       "BP      0.001210\n",
       "XOM     0.000820\n",
       "COST    0.000121\n",
       "GS      0.001406\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of the returns of the stocks\n",
    "stocks.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721cc084",
   "metadata": {},
   "source": [
    "To get the mean for the portfolio we need to multiply this with the stock weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceff2848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00057355, 0.00102234, 0.00023642, 0.0012103 , 0.0008201 ,\n",
       "       0.00012059, 0.00140576])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of means of stock returns\n",
    "stocks.mean().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26fc5c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.2 , 0.2 , 0.15, 0.1 , 0.15, 0.05])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of values of stock weights in our portfolio\n",
    "port.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d201ad3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006897150610100082"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product of the above two gives the expected mean for returns for the portfolio\n",
    "mean_port = port.values[0].dot(stocks.mean().values)\n",
    "mean_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fc461d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>IBM</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>BP</th>\n",
       "      <th>XOM</th>\n",
       "      <th>COST</th>\n",
       "      <th>GS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IBM</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BP</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COST</th>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GS</th>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL       IBM      GOOG        BP       XOM      COST        GS\n",
       "AAPL  0.000217  0.000056  0.000087  0.000079  0.000048  0.000052  0.000090\n",
       "IBM   0.000056  0.000155  0.000053  0.000095  0.000065  0.000024  0.000089\n",
       "GOOG  0.000087  0.000053  0.000157  0.000049  0.000029  0.000049  0.000065\n",
       "BP    0.000079  0.000095  0.000049  0.000343  0.000153  0.000027  0.000168\n",
       "XOM   0.000048  0.000065  0.000029  0.000153  0.000146  0.000021  0.000085\n",
       "COST  0.000052  0.000024  0.000049  0.000027  0.000021  0.000122  0.000046\n",
       "GS    0.000090  0.000089  0.000065  0.000168  0.000085  0.000046  0.000286"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# covariance matrix of the stocks\n",
    "cov_matrix = stocks.cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be82fd27",
   "metadata": {},
   "source": [
    "To get the std for the portfolio we need to multiply this with the stock weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ed7dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.17006162e-04, 5.59911249e-05, 8.74064932e-05, 7.92364963e-05,\n",
       "        4.84425721e-05, 5.15074993e-05, 8.98616572e-05],\n",
       "       [5.59911249e-05, 1.54862010e-04, 5.29871619e-05, 9.52117679e-05,\n",
       "        6.49422577e-05, 2.39766048e-05, 8.94850475e-05],\n",
       "       [8.74064932e-05, 5.29871619e-05, 1.56958485e-04, 4.87019617e-05,\n",
       "        2.93159135e-05, 4.90976612e-05, 6.53544026e-05],\n",
       "       [7.92364963e-05, 9.52117679e-05, 4.87019617e-05, 3.43460461e-04,\n",
       "        1.52618496e-04, 2.65717162e-05, 1.67903311e-04],\n",
       "       [4.84425721e-05, 6.49422577e-05, 2.93159135e-05, 1.52618496e-04,\n",
       "        1.45502012e-04, 2.13323189e-05, 8.46586242e-05],\n",
       "       [5.15074993e-05, 2.39766048e-05, 4.90976612e-05, 2.65717162e-05,\n",
       "        2.13323189e-05, 1.22471562e-04, 4.62853460e-05],\n",
       "       [8.98616572e-05, 8.94850475e-05, 6.53544026e-05, 1.67903311e-04,\n",
       "        8.46586242e-05, 4.62853460e-05, 2.85757711e-04]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# values of covariance of stock returns\n",
    "cov_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bd41622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15, 0.2 , 0.2 , 0.15, 0.1 , 0.15, 0.05])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# array of values of stock weights in our portfolio\n",
    "port.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c2b7e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009049636381388665"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot product of the above two gives the standard deviation for returns for the portfolio\n",
    "# reference from https://www.interviewqs.com/blog/value-at-risk\n",
    "std_port = np.sqrt(port.values[0].dot(cov_matrix.values).dot(port.values[0]))\n",
    "std_port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0127df1",
   "metadata": {},
   "source": [
    "Using the `scipy`'s `norm` we can get the desired values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27c57ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02918ce1",
   "metadata": {},
   "source": [
    "The mean and std of the portfolio are 0.0689% and 0.009, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac3fdda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014195612163509135"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the formulas above, we can calculate the VaR\n",
    "var95_param = norm.ppf(0.95)*std_port - mean_port\n",
    "var95_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fe55276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017977085806165548"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the formulas above, we can calculate the CVaR\n",
    "cvar95_param = (1-0.95)**-1 * norm.pdf(norm.ppf(1-0.95))*std_port - mean_port\n",
    "cvar95_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018282bf",
   "metadata": {},
   "source": [
    "So, the Value-at-Risk using parametric method assuming a normal distribution is 1.42% and Conditional-Value-at-Risk after the VaR exceeds is 1.79% with 5% probability of loss. The results can be summarized in the table below:\n",
    "\n",
    "|            | VaR95% | CVaR95% |\n",
    "|------------|--------|---------|\n",
    "| Historical |  2.15% |  3.14%  |\n",
    "| Parametric |  1.42% |  1.79%  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a1c1f7",
   "metadata": {},
   "source": [
    "> Assume you can change weights, allow shorting but no leverage (i.e. sum of weights equal 100%), and rebalance monthly. What is the optimal portfolio holding by end of each month till end of 2016\n",
    "\n",
    "Here, we can do something similar as above but lets say we calculate the returns at the end of every month and maximise our portfolio returns by adapting weights accordingly. If the returns of a particular stock are on a declining trend, we can use volatility to decrease the weights for that stock, and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea0de5",
   "metadata": {},
   "source": [
    "#### 5. Assume you have a Python project, which source code is under a git repo folder “my-python-project”. Write a program/script to produce the following statistics of this folder:\n",
    "\n",
    "  - How many python files\n",
    "  - How many lines of code in total, how many lines of comment line (empty line doesn’t\n",
    "count)\n",
    "  - How many functions is defined in total\n",
    "  - How many lines of changes from the current version against HEAD~3\n",
    "  - Total folder size (in MB) per each of the subfolder (down to 2 level depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d44b5",
   "metadata": {},
   "source": [
    "There are some readily available tools and packages that can be used to answer these. For the number of python files and lines of code, `pygount` can be used. For the folder sizes, `os` python library can be used. This can also be used to answer the first question. Additionally, there are some online tools available which can summarize a GitHub project. Lines changed between current version against HEAD~3 can be found out using `git`'s `log` or `diff` commands. For the number of functions, am sure there should be a package/library which we can use in our source code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2dab6a",
   "metadata": {},
   "source": [
    "#### 6. In a text file, give me total number of appearance of “date” within the text file. The date format can appears in either one (or multiple) formats shown below:\n",
    "\n",
    "  - YYYY/MM/DD\n",
    "  - MM/DD/YYYY\n",
    "  - DD/MM/YYYY\n",
    "  - DD (Jan/Feb/Mar/Apr/May/Jun/Jul/Aug/Sept/Oct/Nov/Dec) YYYY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4471648",
   "metadata": {},
   "source": [
    "This is a perculiar problem to solve as the data is corrupted. Though there's an easy way address this by using the `pandas` library's `to_datetime()` function. It will convert almost all formats of datetime into a standard format. However, there are a few corner cases which might be good to highlight because of the nature of the data, for example, there is no way to differentiate between MM/DD/YYYY and DD/MM/YYYY for dates less than 13. The library is smart enough to identify month if the date is more than 13 otherwise it will consider it as default format. This is a drawback of the data which cannot be solved even by humans. Secondly, another assumption we make is that the text file contains each date in a new line. We will read the file to a `pandas DataFrame` and then use `to_datetime()` method to convert the dates into a standard format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b7e47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the python library\n",
    "import pandas as pd\n",
    "\n",
    "# import the text file with dates to dataframe\n",
    "df = pd.read_csv('dates.txt', sep='\\n', names=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69577b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021/07/25\n",
      "08/12/2021\n",
      "24/05/2021\n",
      "random word\n",
      "03/25/2021\n",
      "15 Aug 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's see the content of a sample text file\n",
    "with open('dates.txt') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c65bdd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-07-25\n",
       "1   2021-08-12\n",
       "2   2021-05-24\n",
       "3          NaT\n",
       "4   2021-03-25\n",
       "5   2021-08-15\n",
       "Name: date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the dates to datetime format\n",
    "pd.to_datetime(df.date, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b06b1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, the number of dates in the text file\n",
    "pd.to_datetime(df.date.dropna(), errors='coerce').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84cdc45",
   "metadata": {},
   "source": [
    "There are 5 dates in the sample file we used here. Ok, in this case since we assumed that each date was on a separate line we could have just opened the file and counted the number of lines that have some date format. But this code will work for other cases as well, say the dates are separated by other delimiters. In case it is a full text file like an essay, then when reading the file we have use a logic to find the dates first, store them and then convert to dataframe and subsequently to datetime format. There are multiple ways to answer this question depending on use case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
